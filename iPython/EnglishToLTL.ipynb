{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "queries = [\n",
    "    'Did my average speed exceed 5 m/s?', #F(average > 5)\n",
    "    'Did I bike more than 500 meters this week?', #F(tot_dist > 500)\n",
    "    'Did I always stay above an altitude of 50 meters?', #G(attitude > 50)\n",
    "    'Did my speed ever exceed 10 m/s?', #F(attitude > 50)\n",
    "    'Was I always faster than 10 m/s?', #G(speed > 10)\n",
    "    'Did my speed exceed 5 m/s and my altitude always stayed above 50 m?', # F(speed > 5) && G(altitude > 50)\n",
    "    'Did I bike more than 250 meters and go faster than 5 m/s on average?', # F(speed > 5) && F(distance > 50)\n",
    "    'Did I go slower than 5 m/s or bike more than 251 m?' # F(speed > 5) && G(altitude > 50)\n",
    "]\n",
    "\n",
    "\n",
    "triggerPhrases = [\n",
    "    ['did i', 'do i'],\n",
    "    ['how many', 'how much']\n",
    "]\n",
    "# Should contain all //recognizable// words. \n",
    "synonyms = [\n",
    "    ['maintain'], #GF or FG?\n",
    "    ['stay','always'], #G\n",
    "    ['did','ever'], #F\n",
    "    ['greater','exceed','more','faster','above'], # >\n",
    "    ['less','below','slower'], # <\n",
    "    ['after'],\n",
    "    ['until'],\n",
    "    ['speed', 'velocity'],\n",
    "    ['distance'],\n",
    "    ['incline', 'hill'],\n",
    "    ['altitude', 'elevation', 'height'],\n",
    "    ['degree', 'º', '°', 'deg'],\n",
    "    ['mph', 'miles per hour'],\n",
    "    ['meters per second','m/s','ms'],\n",
    "    ['second'],\n",
    "    ['minute'],\n",
    "    ['hour'],\n",
    "    ['meter','m'],\n",
    "    ['foot'],\n",
    "    ['of'],\n",
    "    ['average','mean'],\n",
    "    ['bike','travel'],\n",
    "    ['and','both'],\n",
    "    ['or']\n",
    "]\n",
    "unitWords = [  # Omit s if can be plural\n",
    "    'degree', 'mph', 'second', 'minute', 'hour', 'meter', 'foot', 'meters per second'\n",
    "]\n",
    "modifierWords = [  # Words that modify units\n",
    "    'average','altitude','bike'\n",
    "]\n",
    "connectingWords = [\n",
    "    'of','and','or'\n",
    "]\n",
    "operatorWords = [ # Order matters in this array\n",
    "    'maintain', 'after', 'until', 'greater', 'less', 'did','stay'\n",
    "]\n",
    "variableWords = [\n",
    "    'speed', 'altitude', 'distance', 'incline'\n",
    "]\n",
    "operatorForms = {\n",
    "    'maintain': [\n",
    "        ['maintain', 'BOOL_EXPR', 'VALUE']\n",
    "        ###['maintain', 'BOOL_EXPR', 'until']\n",
    "    ],\n",
    "    'after': [\n",
    "        ['BOOL_EXPR', 'after', 'BOOL_EXPR']\n",
    "    ],\n",
    "    #'until': []\n",
    "    'greater': [\n",
    "        ['REAL_EXPR', 'greater', 'REAL_EXPR']\n",
    "    ],\n",
    "    'less': [\n",
    "        ['REAL_EXPR', 'less', 'REAL_EXPR']\n",
    "    ]\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Create synonymDict mapping all synonyms to their canonical word\n",
    "synonymDict = {}\n",
    "for group in synonyms:\n",
    "    standardWord = group[0]\n",
    "    for word in group:\n",
    "        synonymDict[word] = standardWord\n",
    "\n",
    "all = string.maketrans('','')\n",
    "noDigs = all.translate(all, string.digits)\n",
    "noLetters = all.translate(all, string.letters)\n",
    "allowedLetters = ' abcdefghijklmnopqrstuvwxyz0123456789%.º°'\n",
    "notAllowed = all.translate(all, allowedLetters)\n",
    "def cleanQuery(query):\n",
    "    return query.lower().translate(all, notAllowed)\n",
    "\n",
    "\n",
    "# Attempts to return the canonical words in your query\n",
    "def wordToStandard(word):\n",
    "    if word is None:\n",
    "        return None\n",
    "    word = word.lower()  # Lower case\n",
    "    if len(word) == 0:\n",
    "        return None\n",
    "    if word[0] in '-0123456789':\n",
    "        #TODO: Maybe more processing of numbers\n",
    "        return word\n",
    "    if word in synonymDict:\n",
    "        return synonymDict[word]\n",
    "    word = word.translate(all, noLetters)  # Keep only letters\n",
    "    if word in synonymDict:\n",
    "        return synonymDict[word]\n",
    "    if word[-1] == 's':\n",
    "        word = word[:-1]\n",
    "        if word in synonymDict:\n",
    "            return synonymDict[word]\n",
    "    if word[-2:] == 'ed':\n",
    "        word = word[:-2]\n",
    "        if word in synonymDict:\n",
    "            return synonymDict[word]\n",
    "    return None\n",
    "\n",
    "\n",
    "class Token:\n",
    "    '''A word associated with its meaning'''\n",
    "    # Token types\n",
    "    UNKNOWN = 0\n",
    "    NONE = 1\n",
    "    OPERATOR = 2\n",
    "    CONNECTOR = 3\n",
    "    NUMBER = 4\n",
    "    UNIT = 5\n",
    "    VARIABLE = 6\n",
    "    MODIFIER = 7\n",
    "    def __init__(self, word, left=None, right=None):\n",
    "        self.origWord = word\n",
    "        self.word = wordToStandard(word)\n",
    "        self.left = wordToStandard(left)\n",
    "        self.right = wordToStandard(right)\n",
    "        if self.word in operatorWords:\n",
    "            self.type = Token.OPERATOR\n",
    "        elif self.word in modifierWords:\n",
    "            self.type = Token.MODIFIER\n",
    "        elif self.word in variableWords:\n",
    "            self.type = Token.VARIABLE\n",
    "        elif self.word in unitWords:\n",
    "            self.type = Token.UNIT\n",
    "        elif self.word in connectingWords:\n",
    "            self.type = Token.CONNECTOR\n",
    "        elif len(self.word) > 0 and self.word[0] in '-0123456789':\n",
    "            self.type = Token.NUMBER\n",
    "        else:\n",
    "            self.type = Token.NONE\n",
    "            if self.word is not None:\n",
    "                print repr(self.origWord), repr(self.word), 'not understood.'\n",
    "    def __str__(self):\n",
    "        typeStr = ['UNKNOWN', 'NONE', 'OPERATOR', 'CONNECTOR',\n",
    "                   'NUMBER', 'UNIT', 'VARIABLE','MODIFIER'][self.type]\n",
    "        return '<%s, %s>' % (self.word, typeStr)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "class TokenGroup:\n",
    "    '''A group of tokens that mean somthing as a group'''\n",
    "    # Group types\n",
    "    UNKOWN = 100\n",
    "    VALUE = 101  # Number with unit\n",
    "    BOOL_EXPR = 102  # Logical or temporal\n",
    "    REAL_EXPR = 103\n",
    "    tokenPatterns = {\n",
    "        VALUE: [\n",
    "            [Token.NUMBER, Token.UNIT],\n",
    "            [Token.NUMBER]\n",
    "        ],\n",
    "        BOOL_EXPR: [\n",
    "            # Equality operator\n",
    "            [Token.VARIABLE, Token.CONNECTOR, VALUE],\n",
    "            [VALUE, Token.VARIABLE],\n",
    "            []\n",
    "        ]\n",
    "    }\n",
    "    def __init__(self, type, tokens):\n",
    "        self.type = type\n",
    "        self.tokens = tokens\n",
    "    def __str__(self):\n",
    "        typeStr = ['UNKNOWN', 'VAL', 'EXPRESSION'][self.type-100]\n",
    "        if self.type == TokenGroup.UNKNOWN:\n",
    "            return '<TokenGroup UNKNOWN>'\n",
    "        if self.type == TokenGroup.VALUE:\n",
    "            return '<VAL %s %s>' \n",
    "        if self.type == TokenGroup.BOOL_EXPR:\n",
    "            return '<EXPR>'\n",
    "        if self.type == TokenGroup.REAL_EXPR:\n",
    "            return '<EXPR>'\n",
    "            #return '<%s, %s>' % (repr(self.word), typeStr)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "# This gives you the recognized canonical words\n",
    "def splitQuery(query):\n",
    "    query = cleanQuery(query)\n",
    "    l = query.split()\n",
    "    tokens = []\n",
    "    for word in l:\n",
    "        standard = wordToStandard(word)\n",
    "        if standard is not None:\n",
    "            tokens.append(standard)\n",
    "    return tokens\n",
    "\n",
    "# This will tell you what type each splitted query is\n",
    "def tokenizeQuery(query):\n",
    "    split = splitQuery(query)\n",
    "    tokens = []\n",
    "    for i in xrange(len(split)):\n",
    "        left = None if i-1 < 0 else split[i-1]\n",
    "        right = None if i+1 >= len(split) else split[i+1]\n",
    "        t = Token(split[i], left, right)\n",
    "        if t.type != Token.UNKNOWN and t.type != Token.NONE:\n",
    "            tokens.append(t)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# This will take an array of tokens and then output a dictionary index by Token Types\n",
    "def splitTokensByType(tokens):\n",
    "    # Token types, copied from Token definition\n",
    "    UNKNOWN = 0\n",
    "    NONE = 1\n",
    "    OPERATOR = 2\n",
    "    CONNECTOR = 3\n",
    "    NUMBER = 4\n",
    "    UNIT = 5\n",
    "    VARIABLE = 6\n",
    "    MODIFIER = 7\n",
    "\n",
    "    splitToks = {}\n",
    "    #Separate out tokens by type\n",
    "    for token in tokens:\n",
    "        if token.type == OPERATOR:\n",
    "            if 'OPERATOR' in splitToks and (token.word not in splitToks['OPERATOR']):\n",
    "                splitToks['OPERATOR'].append(token.word)\n",
    "            else:\n",
    "                splitToks['OPERATOR'] = [token.word]\n",
    "        elif token.type == UNIT:\n",
    "            splitToks['UNIT'] = token.word\n",
    "        elif token.type == VARIABLE:\n",
    "            splitToks['VARIABLE'] = token.word\n",
    "        elif token.type == MODIFIER:\n",
    "            if 'MODIFIER' in splitToks:\n",
    "                splitToks['MODIFIER'].append(token.word)\n",
    "            else:\n",
    "                splitToks['MODIFIER'] = [token.word]\n",
    "        elif token.type == NUMBER:\n",
    "            splitToks['NUMBER'] = token.word\n",
    "        else:\n",
    "            pass\n",
    "#             print token.type\n",
    "#             print 'Error'\n",
    "    return splitToks\n",
    "\n",
    "# Determine from tokens which variable you are interested in\n",
    "def determineVariable(splitToks):\n",
    "    if 'VARIABLE' in splitToks: #easy way out\n",
    "        if 'MODIFIER' in splitToks:\n",
    "            if splitToks['MODIFIER'] == ['average']:\n",
    "                return 'average ' + splitToks['VARIABLE']\n",
    "        return splitToks['VARIABLE']\n",
    "    else:\n",
    "        variable = ''\n",
    "        if 'MODIFIER' in splitToks:\n",
    "            if splitToks['MODIFIER'] == ['average']:\n",
    "                variable = variable + 'average '\n",
    "        if 'UNIT' in splitToks:\n",
    "            if splitToks['UNIT'] == 'meters per second':\n",
    "                variable = variable + ' speed'\n",
    "            elif splitToks['UNIT'] == 'meter':\n",
    "                variable = variable + 'distance'\n",
    "        return variable\n",
    "\n",
    "# Determine if query has a F or G operator and returns them if they exist\n",
    "def determineFGOperator(query):\n",
    "    tokens = tokenizeQuery(query)\n",
    "    splitToks = splitTokensByType(tokens)\n",
    "    if 'OPERATOR' in splitToks:\n",
    "        if 'did' in splitToks['OPERATOR']:\n",
    "            return 'did'\n",
    "        elif 'stay' in splitToks['OPERATOR']:\n",
    "            return 'stay'\n",
    "        else:\n",
    "            return ''\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "# Splits a query based on OR and AND, assuming only one of the two is being used\n",
    "def divideQueries(queries):\n",
    "    splitAnd = queries.split(' and ')\n",
    "    splitOr = queries.split(' or ')\n",
    "    andLength = len(splitAnd)\n",
    "    orLength = len(splitOr)\n",
    "    if andLength > orLength:\n",
    "        return (andLength,'AND',splitAnd)\n",
    "    elif orLength > andLength:\n",
    "        return (orLength,'OR',splitOr)\n",
    "    elif (orLength == 1 and andLength == 1):\n",
    "        return (1,'',[queries])\n",
    "    else:\n",
    "        print 'Improperly formatted string'\n",
    "        return ''  \n",
    "\n",
    "def queryToSTL(query):\n",
    "    #Assume only one variable per query        \n",
    "    tokens = tokenizeQuery(query)\n",
    "    splitToks = splitTokensByType(tokens)\n",
    "    numOperators = len(splitToks['OPERATOR'])\n",
    "    for i in xrange(numOperators):        \n",
    "        min_power = 100\n",
    "        min_operator = ''\n",
    "        variable = determineVariable(splitToks)\n",
    "        #Choose the most bad ass operator\n",
    "        for j in xrange(len(splitToks['OPERATOR'])):            \n",
    "            operator = splitToks['OPERATOR'][j]\n",
    "            power = operatorWords.index(operator)\n",
    "            if power < min_power:\n",
    "                min_power = power\n",
    "                min_operator = operator\n",
    "        #Apply the bad ass operator\n",
    "        if variable == '':\n",
    "            if min_operator == 'did':\n",
    "                STL = ('F',STL)\n",
    "            elif min_operator == 'stay':\n",
    "                STL = ('G',STL)            \n",
    "        else:\n",
    "            if min_operator == 'greater':\n",
    "                STL = ('>',variable,splitToks['NUMBER'])\n",
    "            elif min_operator == 'less':\n",
    "                STL = ('<',variable,splitToks['NUMBER'])\n",
    "        rem_tokens = []\n",
    "        if variable != '':            \n",
    "            for token in tokens:\n",
    "                if token.word in variable.split():\n",
    "                    pass\n",
    "                elif token.word == splitToks['NUMBER']:\n",
    "                    pass\n",
    "                elif token.word == splitToks['UNIT']:\n",
    "                    pass\n",
    "                elif token.word == min_operator:\n",
    "                    pass\n",
    "                else:\n",
    "                    rem_tokens.append(token)\n",
    "        else:\n",
    "            if token.word == min_operator:\n",
    "                pass\n",
    "            else:\n",
    "                rem_tokens.append(token)\n",
    "        splitToks = splitTokensByType(rem_tokens)\n",
    "    return STL\n",
    "\n",
    "def queriesToSTL(queries):\n",
    "    result = divideQueries(queries)\n",
    "    numQueries = result[0]\n",
    "    operator = result[1]\n",
    "    extraTok = ''\n",
    "    for i in xrange(numQueries):\n",
    "        token_word = determineFGOperator(result[2][i])\n",
    "        if len(token_word) > 0 and not extraTok: # F or G operator found\n",
    "            extraTok = token_word\n",
    "            for j in xrange(1,numQueries):\n",
    "                result[2][j] = token_word + ' ' + result[2][j]\n",
    "    STL = '' \n",
    "    for i in xrange(numQueries):\n",
    "        partialSTL = queryToSTL(result[2][i])\n",
    "        if i > 0:\n",
    "            STL = (operator,partialSTL,STL)\n",
    "        else:\n",
    "            STL = partialSTL       \n",
    "    return STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did my average speed exceed 5 m/s?\n",
      "('F', ('>', 'average speed', '5'))\n",
      "\n",
      "\n",
      "Did I bike more than 500 meters this week?\n",
      "('F', ('>', 'distance', '500'))\n",
      "\n",
      "\n",
      "Did I always stay above an altitude of 50 meters?\n",
      "('G', ('>', 'distance', '50'))\n",
      "\n",
      "\n",
      "Did my speed ever exceed 10 m/s?\n",
      "('F', ('>', 'speed', '10'))\n",
      "\n",
      "\n",
      "Was I always faster than 10 m/s?\n",
      "('G', ('>', ' speed', '10'))\n",
      "\n",
      "\n",
      "Did my speed exceed 5 m/s and my altitude always stayed above 50 m?\n",
      "('AND', ('G', ('>', 'distance', '50')), ('F', ('>', 'speed', '5')))\n",
      "\n",
      "\n",
      "Did I bike more than 250 meters and go faster than 5 m/s on average?\n",
      "('AND', ('F', ('>', 'average  speed', '5')), ('F', ('>', 'distance', '250')))\n",
      "\n",
      "\n",
      "Did I go slower than 5 m/s or bike more than 251 m?\n",
      "('OR', ('F', ('>', 'distance', '251')), ('F', ('<', ' speed', '5')))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in xrange(len(queries)):\n",
    "    print queries[ind]\n",
    "    tokens = tokenizeQuery(queries[ind])\n",
    "    splitToks = splitTokensByType(tokens)\n",
    "    print queriesToSTL(queries[ind])\n",
    "    print\n",
    "    print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:    Did I bike more than 250 meters and go faster than 5 m/s on average?\n",
      "('AND', ('F', ('>', 'average  speed', '5')), ('F', ('>', 'distance', '250')))\n"
     ]
    }
   ],
   "source": [
    "ind = 6\n",
    "print 'query:   ', queries[ind]\n",
    "tokens = tokenizeQuery(queries[ind])\n",
    "splitToks = splitTokensByType(tokens)\n",
    "print queriesToSTL(queries[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
